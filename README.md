# News_dataset_Models
Welcome to the News Classification Models Repository, a curated collection of machine learning and deep learning models designed for news categorization. This repository serves as a comprehensive resource for exploring various approaches to classifying news articles based on their content.
# Introduction
This is basically the project on the dataset the we have generated by scraping the Hindustan Times news website and we have build the different models based on that dataset.
# Features
The Project has included the deep understanding of the Machine learning , Deep Learning ,Web Scraping and Natural Language Processing

#labels -- {'world':1,'mumbai':2,'Entertainment':3,'india':4,'Lifestyle':5,'cricket':7,'Astrology':6,'Education':8}

All The Models Are Located In The Respective Folders
# Getting Started
If you want to run this project you have clone this repository or download the repository on your local machine and use your choice IDE for running this project. Please Ensure that to update the path of the all dataset according to the your path of dataset. You can Go With Google colab , Jupyter Notebook or VS Code or any IDE You want.
# Prerequisites
List any software, libraries, or dependencies that users need to have installed before they can use your project.
# Website we used - https://www.hindustantimes.com/
# Installation
--Web scraping 1> pip install selenium

-- Models

1>pip install pandas 2>pip install numpy 3>pip install sklearn 4>pip install matplotlib 5>pip install seaborn 6>pip install tensorflow 7>pip install keras 8>pip install gensim

-- Natural language Processing 1>pip install spacy All other installations are mentioned and Guided in the model code.

I Will Prefer You Should create virtual environment and to all installations as it will not cause any dependency problem in future.
# For Project Evalution Consider Neural Network Model.
# Neural Netwoek Model also updated where You can see how to deal with small data and deal with overfitting
# Don't Go With Accuracy The Every Model Got Because Of the Size Of The Dataset We are Considered and the number of classification classes the model got lower accuracy
# That is Model Trying To Overfit The Data You Can Go With Larger Dataset having Good amount of data and if you want to learn how to deal with overfitting refer my updated Neural Model
# In This model building phase i have just skipped some preprocessing steps because i got familiar with the dataset and dataset does not have that much amount of data
# Also Dataset Is Normal and each class having same amount of data but when you are want to go with same model different dataset you must do Data Preprocessing
# In Every Model I have Not used all evalution metrics if You want to use please refer my neural network model you will get code for it.
